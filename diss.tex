% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[backend=biber]{biblatex}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{verbatim}
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex
\usepackage{csquotes}

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable

\addbibresource{sample.bib}

\begin{document}

%\bibliographystyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Kacper Walentynowicz}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{I seriously need to figure out a GOOD title} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
Trinity College \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Name:               & \bf Kacper Walentynowicz                       \\
College:            & \bf Trinity College                     \\
Project Title:      & \bf TBA \\
Examination:        & \bf Computer Science Tripos -- Part II, July 2021  \\
Word Count:         & \bf TBA\footnotemark[1]
                      (well less than the 12000 limit)  \\
Project Originator: & Dr Jagdish Modi                    \\
Supervisors:         & Dr David Greaves, Dr Jagdish Modi                     \\ 
\end{tabular}
}
\footnotetext[1]{This word count was computed
by \texttt{detex diss.tex | tr -cd '0-9A-Za-z $\tt\backslash$n' | wc -w}
}
\stepcounter{footnote}


\section*{Original Aims of the Project}

The original aim of the project was to study several existing approaches to extending known sequential shortest path algorithms for suitability for efficient parallel computation, and to provide their implementation. Because of difficulties in evaluating parallel algorithms, a goal of the project was also to build a simulator which would enable easy implementation and fair comparison of the implemented algorithms.

\section*{Work Completed}

I have successfully implemented the tool which allows simulation of algorithms on various parallel architectures. Then, I have met the other goals of the project by implementing and evaluating several parallel adaptations of known shortest path algorithms: Dijkstra's algorithm, Matrix multiplication algorithm and SPFA algorithm. I have then compared the parallel approaches taking into account both theoretical merits and disadvantages, as well as empirical evaluation on real-world road networks.

\section*{Special Difficulties}

None.
 
\newpage
\section*{Declaration}

I, Kacper Walentynowicz of Trinity College, being a candidate for Part II of the Computer Science Tripos, hereby declare that this dissertation and the work described in it are my own work, unaided except as may be specified below, and that the dissertation does not contain material that has already been used to any substantial
extent for a comparable purpose. I am content for my dissertation to be made available to the students and staff of the University.

\bigskip
\leftline{Signed}
\vspace{20pt}
\par\noindent\rule{\textwidth}{0.4pt}

\medskip
\leftline{Date}
\vspace{20pt}
\par\noindent\rule{\textwidth}{0.4pt}

\newpage
\section*{Acknowledgements}

I am particularly thankful for the support of my two co-supervisors: Dr David Greaves and Dr Jagdish Modi. They have been helping me extensively throughout the project in different ways, both of which were valuable.

I would like to thank Dr Geoff Boeing for providing the incredibly useful OSMNX library for working with OpenStreetMap data\cite{Boeing2017}.

Last but not least, I would like to thank my wife Marta, for her insightful comments on the dissertation, and never-ending willingness to participate in one-sided discussions about the project.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters
\tableofcontents

\pagestyle{headings}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
How much algorithm redesign is needed for parallel architectures? It is certainly not an easy question to answer. For sequential machines, various No Free Lunch theorems \cite{free-lunch} establish that there is no algorithm perfect for all applications. This phenomenon is  visible in parallel systems where communication or synchronization costs may outweigh advantages arising from parallelization, especially if the problem instance is not large. Although there exist attempts at writing software capable of performing efficient parallelizations (such as MIT's pMapper \cite{pmapper}), designing efficient parallel algorithms remains an important challenge. In my project, I have investigated known sequential algorithms for the shortest path problem and considered their different parallel adaptations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Importance of parallel algorithms}
During several previous decades of computing, hardware engineers have been able to deliver better processors as quickly as Gordon Moore had anticipated in the 1970s. Recently, it seems like the boundaries can no longer be pushed as the Moore's Law has slowed down\cite{moore-law}, and programmers will need to resort to alternative ways of achieving speedup. The natural solution is using multiple workers; cores on a single machine or simply several machines communicating together. The most important benefits are energy efficiency and scalability. 

The relationship between clock frequency and used power is non-linear, and therefore to achieve the same performance a single machine needs more energy than a parallel setup. Additionally, machines are suffering from von Neumann bottleneck. The processor and memory are separate, with data moving frequently between them. Latency increasing is an unavoidable consequence of physical distance between destinations, resistance of wires, and other key factors. 

Importance of scalability also cannot be underestimated\footnote{to be precise, it is primarily a feature of distributed systems rather than all parallel ones}. The cost of adding new machines to already existing system is very cheap compared to improving processor designs. 
However, parallel systems are not perfect and generate numerous other difficulties which I'm discussing in section 1.3.

\section{Shortest path problem}
In my dissertation I am studying the shortest paths as an important example of fundamental computer science algorithms. Shortest paths algorithms play an important role in graph theory, also as a building block in more complicated algorithms (such as Minimum Cost Maximum Flow). Additionally, they are prevalent in other domains such as internet routing, route - planning (for vehicles), or planning in robotics. 

Formally, let $G(V,E)$ be a graph with vertex set $V$ and edge set $E$. For our purposes, each edge $i$ ($1\leq i\leq |E|)$ is of the form $(a_i, b_i, w_i)$ and allows moving from vertex $a_i$ to $b_i$ which takes time $w_i$. 

A path between two nodes ($S, T$) is therefore a sequence of edges $e_1$, $e_2$, ..., $e_k$ such that the following hold:
\begin{itemize}
    \item $a_{e_1} = S$
    \item $\displaystyle\mathop{\forall}_{2\leq i \leq k} a_{e_{i}} = b_{e_{i-1}}$
    \item $b_{e_k} = T$
\end{itemize}

Naturally, the shortest path $p_{opt}$ minimizes $\displaystyle\mathop{\sum}_{1\leq i \leq k} w_{e_i}$ among all paths $p$ which satisfy the constraints above.

There exist two main classes of traditional sequential shortest path algorithms: Single-Source Shortest Paths and All-Pairs Shortest Paths. SSSP algorithms calculate for a given node the shortest distances to all the other nodes, while APSP algorithms simply compute the distances between all possible pairs of sources and destinations simultaneously.

\subsection{Single-source shortest paths}
The most famous shortest path algorithm is arguably the Dijkstra's algorithm which is dated to late $1950$s, and described in section $2.3.2$, in the Preparation chapter. Another known shortest path algorithm is named after Bellman and Ford. It has worse theoretical complexity than Dijkstra's, but works even if the edge weights can be negative. Somewhere in the middle between these two lies a simple, yet relatively unknown Shortest Path Faster Algorithm (SPFA) described in detail in section $2.3.3$. The algorithm appears to not have been extensively studied by theoretical computer scientists, but has certain features which should allow an efficient parallel adaptation. Testing whether parallel SPFA can offer a simple and efficient solution for shortest path problems was one of the reasons which inspired me to delve into this project.

\subsection{All-pairs shortest paths}
Another approach which proves efficient especially for dense graphs is to calculate shortest paths in a way which resembles matrix multiplication. Matrix multiplication exhibits a very high degree of parallelism, and therefore this simple method may have good parallel adaptations. Alternatively, one can also consider running one of the above SSSP algorithms $|V|$ times, once for each possible source vertex.

\section{Challenges in parallelization}
Parallelization of an algorithm is not an easy task. In this section I am describing what challenges need to be addressed in order to run code efficiently in parallel.

\subsection{Importance of system architecture} 
Suppose we are doing a computationally expensive task on a system with several workers who carry out tasks. In a dream world, every worker would be able to perform their own work independently, and only report the result once they finish. Unfortunately, life is not perfect like that, and sometimes the workers need to collaborate - share data, report intermediate results, access the same resources, and so on. The costs of these operations may vary \textbf{orders} of magnitude, depending on what are the building blocks of our system. The following table shows the comparison among various possible operation costs\footnote{Author: Peter Norvig, director of research at Google. Table taken from the article: '\textit{Teach yourself programming in 10 years}'}.
\begin{center}
\includegraphics[scale=0.4]{norvig.png}
\end{center}

When talking about classical sequential algorithms these costs are often neglected. In parallel systems communication of workers and their utilization are crucial for efficiency, and therefore need to be carefully considered.

\subsection{Sequential mode of operation}
Some algorithms (such as Dijkstra's) are notoriously difficult to parallelize due to their sequential nature of operation -- later steps depend on earlier steps. A parallel adaptation of a highly efficient sequential algorithm may be truly disappointing if workers are idle majority of the time. On the other hand, simple algorithms may exhibit natural parallelism. Old algorithms which predate computing era are especially promising, as they were not designed with execution on serial machines in mind. One of those is the aforementioned SPFA.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Preparation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Starting point}
Obvious
\section{Requirements analysis}
here: we need a tool for evaluation. requirements for the simulator - addressing some of the challenges above (single and multi threaded, customizable wrt many things to enable experiments, etc)

\section{Algorithms}

\subsection{Matrix multiplication}
here I describe parallel matrix multiplication algorithm, mentioning what challenges are there towards efficient implementation

\subsection{Dijkstra}
here I describe parallel dijkstra, mentioning what challenges are there towards efficient implementation

\subsection{SPFA}
here I describe parallel adaptation of SPFA, what is the idea behind this design (relaxing consistency), why it can be really good in terms of parallellization, mentioning what challenges are there towards efficient implementation (not that many, but still). I hope that I can present this as easy solution if you need a fast algorithm which is not too complicated.

\section{Datasets}
what is OSMNX, why I chose it to get city networks and not artificial graphs, acknowledging Geoff Boeing

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Implementation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Software Development practices}
here I describe what practices I intended to follow: why Java, why python for plotting and osmnx, frequent commit policy, backups on Google Drive

\section{Simulator}

\subsection{Overview}
addressing the requirements, high-level ideas - message passing, primitives, etc. CLEARLY describe which assumptions are taken.

\subsection{Description of building blocks}
I describe what building blocks are there in my simulator, and which are hidden from the outside world but important

\subsubsection{Tasks and Phases}
Task as a main building block. No coroutines, so this solution.

Naturally occurring in algorithms - dependencies between phases, cannot start running phase N+1 until N is finished.

\subsubsection{Scheduler and task runners}
Like a thread-pool. Abstracting away from number of threads used in our algorithms. Hidden from the outside world. 

\subsubsection{Cores and processor architectures}
Arbitrarily powerful entities. Every operation is executed by some core.

\subsubsection{Trackers and Estimators}
Track operations and calculate metrics. Easy changes - just supply a different Estimator class if you want different penalties (addressing requirements... again!).

\subsubsection{Evaluation environment}
Describes the class env, and how the components interact with each other as a system


\section{Parallel matrix multiplication}
I'm thinking whether moving challenges to this section here would make more sense... 
how I addressed the challenges to implement parallel matrix multiplication

\section{Parallel Dijkstra's algorithm}
there are many many challenges here, how can we implement this efficiently

\section{Parallel SPFA implementation}
what is done and why it is done like that

\section{Code testing strategy}
What I am doing to ensure that my algorithms are correct: cross-validation against each other and against networkx libraries

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Evaluation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Theoretical complexities}
This is going to be SHORT. Mat mul is trivial, dijkstra is super complicated and SPFA is unproven... Is it even necessary? 

\section{Execution times}
Plots related solely to execution times go here. Will try to write models and fit with scikit-learn.

\section{Energy efficiency}
Is the algorithm energy-efficient? Energy usage, power consumption, estimated as total work performed among cores.

\section{Sensitivity analysis}
In this chapter I'm going to perform perturbations of various parameters and calculate how the results change to be able to confidently report results.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Well... I don't know what the conclusions are going to be! It would be good to say that everything was evaluated successfully, and we demonstrated some interesting results... 

\section{Future work}
What else interesting can be done

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}
\printbibliography

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\chapter{Latex source}

%\section{diss.tex}
%{\scriptsize\verbatiminput{diss.tex}}

%\section{proposal.tex}
%{\scriptsize\verbatiminput{proposal.tex}}

%\chapter{Makefile}

%\section{makefile}\label{makefile}
%{\scriptsize\verbatiminput{makefile.txt}}

%\section{refs.bib}
%{\scriptsize\verbatiminput{refs.bib}}

\chapter{Project Proposal}

%\input{proposal}

\end{document}
